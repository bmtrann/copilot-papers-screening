@article{rayyan-384038179,
  title={Enhancing {Kubernetes} security with machine learning: а proactive approach to anomaly detection; Повышение безопасности {Kubernetes} с использованием машинного обучения: проактивный подход к обнаружению аномалий},
  year={2024},
  journal={Scientific and Technical Journal of Information Technologies, Mechanics and Optics},
  volume={24},
  number={6},
  pages={1007 -- 1015},
  author={Darwesh, Ghadeer and Hammoud, Jaafar and Vorobeva, Alisa A.},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213480307&doi=10.17586%2F2226-1494-2024-24-6-1007-1015&partnerID=40&md5=f5c909444faebc653fa08d6fac55c15b},
  abstract={Kubernetes has become a cornerstone of modern software development enabling scalable and efficient deployment of microservices. However, this scalability comes with significant security challenges, particularly in detecting specific attack types within dynamic and ephemeral environments. This study presents a focused application of Machine Learning (ML) techniques to enhance security in Kubernetes by detecting Denial of Service (DoS) attacks and differentiating between DoS attacks, resource overload caused by attacks, and natural resource overloads. We developed a custom monitoring agent that collects telemetry data from various sources, including real-world workloads, actual attack scenarios, simulated hacking attempts, and induced overloading on containers and pods, ensuring comprehensive coverage. The dataset comprising these diverse sources was meticulously labeled and preprocessed, including normalization and temporal analysis. We employed and evaluated various ML classifiers, with Random Forest and AdaBoost emerging as the top performers, achieving F1 macro scores of 0.9990 ± 0.0006 and 0.9990 ± 0.0003, respectively. The novelty of our approach lies in its ability to accurately distinguish between different types of resource overloads and provide robust detection of DoS attacks within Kubernetes environments. These models demonstrated a high degree of accuracy in detecting security incidents, significantly reducing false positives and false negatives. Our findings highlight the potential of ML models to provide a targeted, proactive security framework for Kubernetes, offering robust protection against specific attack vectors while maintaining system reliability. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Article},
  doi={10.17586/2226-1494-2024-24-6-1007-1015},
  chapter={0}
}

@article{rayyan-384038180,
  title={A {Novel} {Framework} for {Cross}-{Cluster} {Scaling} in {Cloud}-{Native} {5G} {NextGen} {Core}},
  year={2024},
  journal={Future Internet},
  volume={16},
  number={9},
  author={Dumitru-Guzu, Oana Mihaela and Vlədeanu, Cəlin and Kooij, Robert E.},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205218572&doi=10.3390%2Ffi16090325&partnerID=40&md5=926a133cf24be6fd2fac915780a70600},
  keywords={Cloud platforms, Cluster computing, Control planes, Distributed cloud, Resource allocation, 5G mobile communication systems, Horizontal scaling, Liquid computing, Multi-clouds, Multi-cluster, Network slicing, NEXTGEN, On demands, Scalings, Vertical scaling},
  abstract={Cloud-native technologies are widely considered the ideal candidates for the future of vertical application development due to their boost in flexibility, scalability, and especially cost efficiency. Since multi-site support is paramount for 5G, we employ a multi-cluster model that scales on demand, shifting the boundaries of both horizontal and vertical scaling for shared resources. Our approach is based on the liquid computing paradigm, which has the benefit of adapting to the changing environment. Despite being a decentralized deployment shared across data centers, the 5G mobile core can be managed as a single cluster entity running in a public cloud. We achieve this by following the cloud-native patterns for declarative configuration based on Kubernetes APIs and on-demand resource allocation. Moreover, in our setup, we analyze the offloading of both the Open5GS user and control plane functions under two different peering scenarios. A significant improvement in terms of latency and throughput is achieved for the in-band peering, considering the traffic between clusters is ensured by the Liqo control plane through a VPN tunnel. We also validate three end-to-end network slicing use cases, showcasing the full 5G core automation and leveraging the capabilities of Kubernetes multi-cluster deployments and inter-service monitoring through the applied service mesh solution. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Article},
  doi={10.3390/fi16090325},
  chapter={0}
}

@article{rayyan-384038182,
  title={Telemetry to solve dynamic analysis of a distributed system},
  year={2024},
  journal={Journal of Edge Computing},
  volume={3},
  number={1},
  pages={87 -- 109},
  author={Talaver, Oleh V. and Vakaliuk, Tetiana A.},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005456183&doi=10.55056%2Fjec.728&partnerID=40&md5=9e8192a211d4a46f70e800008fc60c08},
  abstract={In the modern software development world, implementing distributed solutions has become quite common due to the flexibility it brings to big companies. The downside is that when developing such systems, especially in many teams, global design problems may not be obvious and lead to a slowdown in the development process or even problems with the location of errors or degradation of overall system performance. In addition, the timely reaction to system degradation is complicated by the distributed nature of the architecture; while manually configuring rules for reporting problematic situations can be time-consuming and still incomplete, automatic detection of possible system anomalies will give engineers (especially Software Reliability Engineers) the focus on problems. For this reason, applications that can dynamically analyse the system for problems have great potential. Currently, the topic of using telemetry for system analysis is actively studied and gaining traction, so further research is valuable. The work aims to theoretically and practically prove the possibility of using telemetry to analyse a distributed information system and detect harmful architectural practices and anomalous events. To do this, firstly, a detailed overview of the problems related to the topic and the feasibility of using telemetry is provided; the next section briefly describes the history of the development of monitoring systems and the key points of the latest OpenTelemetry standard, reviews popular application performance monitoring systems, and defines innovative features to be further researched. The main part includes an explanation of the approach used to collect and process telemetry, a reasoning behind the usage of Neo4j as a data storage solution, a practical overview of graph theory algorithms that help in the analysis of the collected data, and a description outlining how the PCA algorithm is employed to detect unusual situations in the whole system instead of individual metrics. The results provide an example of using the software presented with Neo4j Bloom to visualise and analyse the data collected over several hours from the OpenTelemetry Demo test system. The last section contains additional remarks on the results of the study.$^{\textrm{1}}$. © 2025 Elsevier B.V., All rights reserved.},
  note={Type: Article},
  doi={10.55056/jec.728},
  chapter={0}
}

@article{rayyan-384038184,
  title={Unraveling the complex challenges and innovative solutions in microservice architecture: {Exploring} deep microservice architecture hurdles},
  year={2024},
  pages={177 -- 194},
  author={Patel, Kaushikkumar},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191775054&doi=10.4018%2F979-8-3693-1682-5.ch011&partnerID=40&md5=b3e58fefb10b433ad034ca3cc4fd9a7a},
  abstract={This chapter delves into the challenges of microservice architecture within serverless computing, outlining strategic remedies. It underscores operational hurdles like sophisticated orchestration and service interactions, along with security concerns due to the system's decentralized fabric. The discourse extends to performance bottlenecks, focusing on resource management in serverless frameworks. Proposed solutions include advanced system monitoring, state-of-the-art security safeguards, and innovative optimization strategies. The chapter concludes with prospective research directions, emphasizing advanced service meshes and security enhancements, offering practitioners a pragmatic blueprint for microservice implementation in serverless infrastructures. This analysis is crucial for professionals navigating the intricacies of microservice deployment. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Book chapter},
  doi={10.4018/979-8-3693-1682-5.ch011},
  chapter={0}
}

@article{rayyan-384038189,
  title={Using {Observability} to {Detect} {Anti}-patterns in {Benchmarking} {Application} with {OpenTelemetry}},
  year={2024},
  author={de Almada Gomes, Francisco Anderson and Rocha, Lincoln Souza and Rego, Paulo Antonio Leal and Trinta, Fernando Antonio Mota},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217088151&doi=10.1109%2FCloudNet62863.2024.10815858&partnerID=40&md5=04c69e5bb580849fca161abde039d669},
  keywords={Performance, Benchmarking, Software-systems, Application programs, Systems architecture, Anti-patterns, Continuous time systems, Design decisions, Mi-croservice, Monolithics, Risk of failure, Software architecture, System quality, Systems performance},
  abstract={The microservices architecture emerged in response to the increasing scale and complexity of modern software systems, enabling continuous scalability and addressing the challenges of complex monolithic codebases. However, the growing complexity of cloud-native applications also increases the risks of failures. Additionally, design decisions in these applications can manifest as anti-patterns, recurring practices that, while seemingly effective, lead to negative consequences and compromise system quality. This study evaluates the effectiveness of observability in detecting anti-patterns in a microservices-based benchmarking application, contributing to the improvement of the system's architecture and performance by utilizing the OpenTelemetry (OTel) framework. A total of three anti-patterns were detected: Chatty Services, Wobbly Service Interactions, and Cyclic Dependency. Our experiments demonstrated that by resolving the detected anti-patterns, the response time decreased by 9.38\%, improving the application's performance and consequently enhancing the user experience. © 2025 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1109/CloudNet62863.2024.10815858},
  chapter={0}
}

@article{rayyan-384038191,
  title={Assisting {Offshore} {Production} {Optimization} {Technology} in {Intelligent} {Completion} {Operation} {Based} on {Edge}-{Cloud} {Collaborative} {Technologies}},
  year={2024},
  author={Cheng, Zhong and Zhang, Liang and Hao, Zhouzheng and Qu, Shaolin and Liu, Jingchao and Ding, Xiangxiang and Liu, Chuangang and Li, Ning and Li, Ruifeng},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215124912&doi=10.2118%2F222157-MS&partnerID=40&md5=fcfe9b6669379362111958ef01da80ac},
  keywords={Cloud platforms, Benchmarking, Edge computing, Decision making, Empowerment of personnel, Petroleum reservoir evaluation, Quality of service, Six sigma, Cloud-based, Collaborative technologies, Competitive intelligence, Completion technology, Digital oilfield, Drill strings, Drilling platforms, Edge clouds, Edge-cloud collaborative, Exploratory oil well drilling, Finance, Intelligent completion, Intelligent well technology, Multi wells, Natural gas well completion, Offshore gas well production, Offshore gas wells, Offshore oil well production, Offshore oil wells, Offshore petroleum prospecting, Oil and gas well, Oil well completion, Oil well flooding, Production control, Production optimization, Production platforms, Radioactivity logging, Rock bursts, Thermal logging, Waste treatment},
  abstract={This paper demonstrates the enhancement of intelligent completion capabilities by integrating with a digital oilfield platform for effective performance management of offshore wells. The development of intelligent completion technologies has been increasingly important in the field of oil exploration and production in the last few years. The development of an integrated system based on edge-cloud collaborative technologies is in line with the company's objectives of building offshore intelligent oilfields. This is the result of the integration of intelligent completion technology with digital advancements. The use of this technology addresses multi-well operations, reservoir complexity, formation pressure, production challenges, and substantial cost optimization in offshore environments. The integrated well-completion system comprises a cloud-based analytics management application, downhole sensors, downhole flow control tools, and on-site data gathering, analysis, and control devices. The main activities at the edge end are data processing and collection, which includes feature extraction, consistency validation, feature engineering, and data supplementation. Real-time data monitoring, analysis, and production optimization are carried out using constrained computational resources, with a focus on production activities, using simplified multi-field coupling analysis models; Obtaining drilling and completion data for various offshore oil and gas wells as well as reservoir analysis data from the production phase are the tasks involved at the cloud end. The system uses newly developed reservoir-wellbore multi-field coupling non-steady-state models for oil and gas well production analysis, combining real-time monitoring data from the offshore platform. It quickly offers medium-term and short-term production optimization solutions, with an emphasis on managing the production of oil and gas wells. The deployment of computational analysis models and the application of multi-well production optimization strategies are made possible by edge-cloud collaboration technology, which also maintains a reasonable degree of autonomy between on-site and remote management. These components are fully integrated and interact with each other to function as microservices, cloud-based container services, or edge computing services, providing a one-stop solution for improving reservoir management as it enables remote control and monitoring of downhole equipment. The core of this paper is to provide a technical overview for the effective integration of data from leading performance indicators attributing to intelligent completions, with the ultimate goal of optimizing reservoir recovery and phasing out the load of high OPEX to CAPEX by using downhole communication, advanced digital software, remote sensing, and control devices, and telemetry to transmit the massive amount of data gathered. © 2025 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.2118/222157-MS},
  chapter={0}
}

@article{rayyan-384038194,
  title={Unleashing {Performance} {Insights} with {Online} {Probabilistic} {Tracing}},
  year={2024},
  pages={72 -- 82},
  author={Toslali, Mert and Qasim, S. and Parthasarathy, Srinivasan and Oliveira, Fábio A. and Huang, Hai and Stringhini, Gianluca and Liu, Z. and Coşkun, Ayşe Kıvılcım},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212219348&doi=10.1109%2FIC2E61754.2024.00015&partnerID=40&md5=bf064c0c16a074bf003929c59c44e0bf},
  keywords={Cloud-computing, Microservice, Performance, Cloud platforms, Distributed systems, Distributed tracing, Distributed cloud, Fundamental tools, Markov processes, On-line Bayesian learning, Performance diagnosis, Performance variations, Probabilistics},
  abstract={Distributed tracing has become a fundamental tool for diagnosing performance issues in the cloud by recording causally ordered, end-to-end workflows of request executions. However, tracing workloads in production can introduce significant overheads due to the extensive instrumentation needed for identifying performance variations. This paper addresses the trade-off between the cost of tracing and the utility of the 'spans' within that trace through Astraea, an online probabilistic distributed tracing system. Astraea is based on our technique that combines online Bayesian learning and multi-armed bandit frameworks. This formulation enables Astraea to effectively steer tracing towards the useful instrumentation needed for accurate performance diagnosis. Astraea localizes performance variations using only 20-35\% of available instrumentation, markedly reducing tracing overhead, storage, compute costs, and trace analysis time. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1109/IC2E61754.2024.00015},
  chapter={0}
}

@article{rayyan-384038195,
  title={A {Deep} {Graph} {Neural} {Networks} {Approach} for {Service} {Failure} {Analytics}},
  year={2024},
  pages={298 -- 301},
  author={Ba-Hung, Nguyenba and Yabusaki, Hitoshi and Sagara, Takahiro},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211206849&doi=10.1109%2FFiCloud62933.2024.00053&partnerID=40&md5=d808dfa5bd243ee65482a51a7cf9fefe},
  keywords={Telemetry data, Graph neural networks, Cloud-based, Failure detection, Hidden services, High reliability, In-service failures, Service failure, Traditional approaches, Traditional approachs},
  abstract={Microservices make it challenging for operators of cloud-based services to keep higher reliability. To strive for better reliability in service failure detection, some solutions use traditional approaches in their analytics that lead to missing or loss of important characteristics of telemetry data and thus cannot detect the impact of service failure on users. To enhance the detection of the impact of service failure, this paper contributes (i) a hidden service failure scenario based on a realistic use case, and (ii) a deep graph neural networks-based approach for improving service failure analytics. We built deep graph neural networks (DGNNs) to capture the diverse characteristics of telemetry data from observability practice. Our evaluation results, which are built on a digital payment use case, showed that DGNNs improved the detection rate of service failures by more than 30 percentage points compared to the traditional machine learning approaches. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1109/FiCloud62933.2024.00053},
  chapter={0}
}

