@article{rayyan-384037956,
  title={A study of real-world data races in Golang - Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  year={2022},
  pages={474–489},
  author={Chabbi, Milind and Ramanathan, Murali Krishna},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3519939.3523720},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={PLDI 2022},
  keywords={Data race, Dynamic analysis, Golang},
  abstract={The concurrent programming literature is rich with tools and techniques for data race detection. Less, however, has been known about real-world, industry-scale deployment, experience, and insights about data races. Golang (Go for short) is a modern programming language that makes concurrency a first-class citizen. Go offers both message passing and shared memory for communicating among concurrent threads. Go is gaining popularity in modern microservice-based systems. Data races in Go stand in the face of its emerging popularity.    In this paper, using our industrial codebase as an example, we demonstrate that Go developers embrace concurrency and show how the abundance of concurrency alongside language idioms and nuances make Go programs highly susceptible to data races. Google’s Go distribution ships with a built-in dynamic data race detector based on ThreadSanitizer. However, dynamic race detectors pose scalability and flakiness challenges; we discuss various software engineering trade-offs to make this detector work effectively at scale. We have deployed this detector in Uber’s 46 million lines of Go codebase hosting 2100 distinct microservices, found over 2000 data races, and fixed over 1000 data races, spanning 790 distinct code patches submitted by 210 unique developers over a six-month period. Based on a detailed investigation of these data race patterns in Go, we make seven high-level observations relating to the complex interplay between the Go language paradigm and data races.},
  doi={10.1145/3519939.3523720},
  booktitle={Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  chapter={0}
}

@article{rayyan-384037957,
  title={Detailed black-box monitoring of distributed systems},
  year={2021},
  month={7},
  journal={SIGAPP Appl. Comput. Rev.},
  issn={1559-6915},
  volume={21},
  number={1},
  pages={24–36},
  author={Neves, Francisco and Vila\c{c}a, Ricardo and Pereira, Jos\'{e}},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3477133.3477135},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  keywords={monitoring, containers, adaptive placement},
  abstract={Modern containerized distributed systems, such as big data storage and processing stacks or micro-service based applications, are inherently hard to monitor and optimize, as resource usage does not directly match hardware resources due to multiple virtualization layers. For instance, interapplication traffic is an important factor in as it directly indicates how components interact, it has not been possible to accurately monitor it in an application independent way and without severe overhead, thus putting it out of reach of cloud platforms.In this paper we present an efficient black-box monitoring approach for gathering detailed structural information of collaborating processes in a distributed system that can be queried for various purposes, as it includes both information about processes, containers, and hosts, as well as resource usage and amount of data exchanged. The key to achieving high detail and low overhead without custom application instrumentation is to use a kernel-aided event driven strategy. We validate a prototype implementation by applying it to multi-platform microservice deployments, evaluate its performance with micro-benchmarks, and demonstrate its usefulness for container placement in a distributed data storage and processing stack (i.e., Cassandra and Spark).},
  doi={10.1145/3477133.3477135},
  chapter={0}
}

@article{rayyan-384037958,
  title={Nonlinear Dynamics Methods for Analysis of ECG Signals - Proceedings of the 21st International Conference on Computer Systems and Technologies},
  year={2020},
  pages={194–200},
  author={Gospodinova, Evgeniya and Gospodinov, Mitko and Negreva, Maria},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3407982.3408000},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={CompSysTech '20},
  keywords={RR time series, largest Lyapunov exponent and Poincar\'{e} plot, reconstructed phase space analysis},
  abstract={Nonlinear dynamics methods are increasingly used in the process of information analysis of electrocardiogram (ECG) signals due to the fact that they enable the monitoring of heart rate dynamics. These methods complement the traditional analysis performed by applying the linear methods (Time- and Frequency-Domain). This article presents the results of the study of the nonlinear dynamic characteristics of the time intervals between heart intervals (RR time series), through the application of the following methods of the nonlinear dynamics: reconstructed phase space analysis, largest Lyapunov exponent and Poincar\'{e} plot. Two groups of people were studied: healthy and unhealthy subjects (patients with heart failure). The performed statistical analysis of the calculated characteristics describing the nonlinear dynamics of the RR time series show that it differ significantly between the two groups studied. Therefore, the application of these methods may be helpful in the diagnosis of cardiovascular disease. The introduction of nonlinear dynamics methods as well as linear ECG signal analysis methods requires information technology professionals to actively collaborate with cardiologists to integrate these new methods into clinical practice to support physician activity in diagnosis and early detection of cardiovascular diseases. The analysis of the investigated signals was performed by applying a web-based application using a serverless architecture, which is experimental and has no commercial purpose.},
  doi={10.1145/3407982.3408000},
  booktitle={Proceedings of the 21st International Conference on Computer Systems and Technologies},
  chapter={0}
}

@article{rayyan-384037959,
  title={On the Accuracy of Country-Level IP Geolocation - Proceedings of the 2020 Applied Networking Research Workshop},
  year={2020},
  pages={67–73},
  author={Livadariu, Ioana and Dreibholz, Thomas and Al-Selwi, Anas Saeed and Bryhni, Haakon and Lysne, Olav and Bj\o{}rnstad, Steinar and Elmokashfi, Ahmed},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3404868.3406664},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={ANRW '20},
  keywords={Geolocation Approaches, Geolocation Databases, IP Geolocation},
  abstract={The proliferation of online services comprised of globally spread microservices has security and performance implications. Understanding the underlying physical paths connecting end points has become important. This paper investigates the accuracy of commonly used IP geolocation approaches in geolocating end-to-end IP paths. To this end, we perform a controlled measurement study to collect IP level paths. We find that existing databases tend to geolocate IPs that belong to networks with global presence and those move between networks erroneously. A small percentage of IP geolocation disagreement between databases results in a significant disagreement when geolocating end-to-end paths. Geolocating one week of RIPE traceroute data validates our observations.},
  doi={10.1145/3404868.3406664},
  booktitle={Proceedings of the 2020 Applied Networking Research Workshop},
  chapter={0}
}

@article{rayyan-384037960,
  title={FlowCon: Elastic Flow Configuration for Containerized Deep Learning Applications - Proceedings of the 48th International Conference on Parallel Processing},
  year={2019},
  author={Zheng, Wenjia and Tynes, Michael and Gorelick, Henry and Mao, Ying and Cheng, Long and Hou, Yantian},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3337821.3337868},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={ICPP '19},
  keywords={resource management, high performance analytics, deep learning, containerized application, cloud computing},
  abstract={An increasing number of companies are using data analytics to improve their products, services, and business processes. However, learning knowledge effectively from massive data sets always involves nontrivial computational resources. Most businesses thus choose to migrate their hardware needs to a remote cluster computing service (e.g., AWS) or to an in-house cluster facility which is often run at its resource capacity. In such scenarios, where jobs compete for available resources utilizing resources effectively to achieve high-performance data analytics becomes desirable. Although cluster resource management is a fruitful research area having made many advances (e.g., YARN, Kubernetes), few projects have investigated how further optimizations can be made specifically for training multiple machine learning (ML) / deep learning (DL) models. In this work, we introduce FlowCon, a system which is able to monitor loss functions of ML/DL jobs at runtime, and thus to make decisions on resource configuration elastically. We present a detailed design and implementation of FlowCon, and conduct intensive experiments over various DL models. Our experimental results show that FlowCon can strongly improve DL job completion time and resource utilization efficiency, compared to existing approaches. Specifically, FlowCon can reduce the completion time by up to 42.06\% for a specific job without sacrificing the overall makespan, in the presence of various DL job workloads.},
  doi={10.1145/3337821.3337868},
  booktitle={Proceedings of the 48th International Conference on Parallel Processing},
  chapter={0}
}

@article{rayyan-384037961,
  title={Noisy neighbor detection using skydive - Proceedings of the 12th ACM International Conference on Systems and Storage},
  year={2019},
  pages={189},
  author={Zeilig, Ofir and Bratman, Noa and Ashkenazi, Itzik and Raichstein, Eran and Levin, Anna and Barabash, Katherine},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3319647.3325850},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={SYSTOR '19},
  abstract={Cloud computing technology enables uniform access to shared pools of configurable system resources and higher-level services, rapidly provisioned with minimal management effort. Cloud computing relies on sharing the resources to achieve coherence and economies of scale, through virtualizion. Cloud network, in particular, is virtualized through multiple logical constructs and SW layers, making cloud connectivity complex to configure, debug, and visualize. In this work, we show how to detect cloud network operational issues through monitoring and analytics, using and enhancing open source network analyzer, Skydive [2]. In particular, we focus on Noisy Neighbor Effect, a situation in which a common resource is monopolized by a noisy tenant, resulting in performance degradation experienced by other tenants.Skydive is an open-source network topology and protocol analyzer, capable of discovering and visualizing cloud network topology across its multiple layers, as well as capturing network traffic at programmable granularity, injecting network traffic, and more. Typical Skydive setup consists of multiple Skydive agents installed on various network components and one or more Skydive analyzers deployed on any compute resource in the cloud. Skydive agents discover and report the information to a Skydive analyzer, that stores it over time so it can be consumed via Web UI, command line tools, and REST API, for visualization, exploration, and analytics.In our work we used Skydive to investigate and detect the Noisy Neighbor Effect in Kubernetes (k8s) network. Our setup consisted of a commercial cloud platform, IBM Cloud Private (ICP) [1], running an HTTP server and two HTTP clients constantly sending requests to the server, all 3 are containerized Python applications as shown in Figure 1. We have installed Skydive agents on all the k8s worker nodes.To achieve our goal of detecting anomalous client behavior and creating a visual indication of such anomaly in Skydive UI, we have enhanced Skydive capabilities and contributed our enhancements back to the project by extending the Python REST client library to support traffic injections, and fixing existing bugs in the Skydive system.We used those enhancements to measure Round Trip Time (RTT) between nodes in the cloud network, detect anomalies in RTT measurements and indicate them in Skydive UI, such as the green indication in Figure 1.In this work, we have made the first step towards automatic detection of Noisy Neighbor with Skydive, using simple threshold based approach, in an experimental setup. This work can be extended in a multiple ways - support more generic and realistic multi-tenant setup; employ deeper analyses, e.g. ML and DL, also on historical data; explore additional anomalous cases, beyond the Noisy Neighbor Effect.},
  doi={10.1145/3319647.3325850},
  booktitle={Proceedings of the 12th ACM International Conference on Systems and Storage},
  chapter={0}
}

@article{rayyan-384037962,
  title={Investigating and improving log parsing in practice - Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  year={2022},
  pages={1566–1577},
  author={Fu, Ying and Yan, Meng and Xu, Jian and Li, Jianguo and Liu, Zhongxin and Zhang, Xiaohong and Yang, Dan},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3540250.3558947},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={ESEC/FSE 2022},
  keywords={Log parsing, Log analysis, Industrial study},
  abstract={Logs are widely used for system behavior diagnosis by automatic log mining. Log parsing is an important data preprocessing step that converts semi-structured log messages into structured data as the feature input for log mining. Currently, many studies are devoted to proposing new log parsers. However, to the best of our knowledge, no previous study comprehensively investigates the effectiveness of log parsers in industrial practice. To investigate the effectiveness of the log parsers in industrial practice, in this paper, we conduct an empirical study on the effectiveness of six state-of-the-art log parsers on 10 microservice applications of Ant Group. Our empirical results highlight two challenges for log parsing in practice: 1) various separators. There are various separators in a log message, and the separators in different event templates or different applications are also various. Current log parsers cannot perform well because they do not consider various separators. 2) Various lengths due to nested objects. The log messages belonging to the same event template may also have various lengths due to nested objects. The log messages of 6 out of 10 microservice applications at Ant Group with various lengths due to nested objects. 4 out of 6 state-of-the-art log parsers cannot deal with various lengths due to nested objects. In this paper, we propose an improved log parser named Drain+ based on a state-of-the-art log parser Drain. Drain+ includes two innovative components to address the above two challenges: a statistical-based separators generation component, which generates separators automatically for log message splitting, and a candidate event template merging component, which merges the candidate event templates by a template similarity method. We evaluate the effectiveness of Drain+ on 10 microservice applications of Ant Group and 16 public datasets. The results show that Drain+ outperforms the six state-of-the-art log parsers on industrial applications and public datasets. Finally, we conclude the observations in the road ahead for log parsing to inspire other researchers and practitioners.},
  doi={10.1145/3540250.3558947},
  booktitle={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  chapter={0}
}

@article{rayyan-384037963,
  title={Monitorless: Predicting Performance Degradation in Cloud Applications with Machine Learning - Proceedings of the 20th International Middleware Conference},
  year={2019},
  pages={149–162},
  author={Grohmann, Johannes and Nicholson, Patrick K. and Iglesias, Jesus Omana and Kounev, Samuel and Lugones, Diego},
  url={https://doi-org.proxy-ub.rug.nl/10.1145/3361525.3361543},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  series={Middleware '19},
  keywords={Monitoring, Machine learning, DevOps, Cloud computing},
  abstract={Today, software operation engineers rely on application key performance indicators (KPIs) for sizing and orchestrating cloud resources dynamically. KPIs are monitored to assess the achievable performance and to configure various cloud-specific parameters such as flavors of instances and autoscaling rules, among others. Usually, keeping KPIs within acceptable levels requires application expertise which is expensive and can slow down the continuous delivery of software. Expertise is required because KPIs are normally based on application-specific quality-of-service metrics, like service response time and processing rate, instead of generic platform metrics, like those typical across various environments (e.g., CPU and memory utilization, I/O rate, etc.)In this paper, we investigate the feasibility of outsourcing the management of application performance from developers to cloud operators. In the same way that the serverless paradigm allows the execution environment to be fully managed by a third party, we discuss a monitorless model to streamline application deployment by delegating performance management. We show that training a machine learning model with platform-level data, collected from the execution of representative containerized services, allows inferring application KPI degradation. This is an opportunity to simplify operations as engineers can rely solely on platform metrics -- while still fulfilling application KPIs -- to configure portable and application agnostic rules and other cloud-specific parameters to automatically trigger actions such as autoscaling, instance migration, network slicing, etc.Results show that monitorless infers KPI degradation with an accuracy of 97\% and, notably, it performs similarly to typical autoscaling solutions, even when autoscaling rules are optimally tuned with knowledge of the expected workload.},
  doi={10.1145/3361525.3361543},
  booktitle={Proceedings of the 20th International Middleware Conference},
  chapter={0}
}

