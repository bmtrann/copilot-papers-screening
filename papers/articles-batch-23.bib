@article{rayyan-384038138,
  title={ViperProbe: Rethinking Microservice Observability with eBPF - 2020 IEEE 9th International Conference on Cloud Networking (CloudNet)},
  year={2020},
  month={11},
  pages={1-8},
  author={Levin, Joshua and Benson, Theophilus A.},
  keywords={Measurement;Runtime;Tools;Software;Observability;Task analysis;Monitoring},
  abstract={Recent shifts to microservice-based architectures and the supporting servicemesh radically disrupt the landscape of performance-oriented management tasks. While the adoption of frameworks like Istio and Kubernetes ease the management and organization of such systems, they do not themselves provide strong observability. Microservice observability requires diverse, highly specialized, and often adaptive, metrics and algorithms to monitor both the health of individual services and the larger application. However, modern metrics collection frameworks are relatively static and rigid. We introduce ViperProbe, an eBPF-based microservices collection framework that provides (1) dynamic sampling and (2) collection of deep, diverse, and precise system metrics. Viper-Probe builds on the observation that the adoption of a common set of design patterns, e.g., servicemesh, enables offline analysis. By examining the performance profile of these patterns before deploying on production, ViperProbe can effectively reduce the set of collected metrics, thereby improving the efficiency and effectiveness of those metrics. To the best of our knowledge, ViperProbe is the first scalable eBPF-based dynamic and adaptive microservices metrics collection framework. Our results show ViperProbe has limited overhead, while significantly more effective for traditional management tasks, e.g., horizontal autoscaling.},
  doi={10.1109/CloudNet51028.2020.9335808},
  booktitle={2020 IEEE 9th International Conference on Cloud Networking (CloudNet)},
  chapter={0}
}

@article{rayyan-384038139,
  title={Kmon: An In-kernel Transparent Monitoring System for Microservice Systems with eBPF - 2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)},
  year={2021},
  month={5},
  pages={25-30},
  author={Weng, Tianjun and Yang, Wanqi and Yu, Guangba and Chen, Pengfei and Cui, Jieqi and Zhang, Chuanfu},
  keywords={Measurement;Industries;Instruments;Conferences;Memory management;Software systems;Information fil...},
  abstract={Currently, the architecture of software systems is shifting from “monolith” to “microservice” which is an important enabling technology of cloud native systems. Since the advantages of microservice in agility, efficiency, and scaling, it has become the most popular architecture in the industry. However, as the increase of microservice complexity and scale, it becomes challenging to monitor such a large number of microservices. Traditional monitoring techniques such as end-to-end tracing cannot well fit microservice environment, because they need code instrumentation with great effort. Moreover, they cannot explore the fine-grained internal states of microservice instances. To tackle this problem, we propose Kmon, which is an In-kernel transparent monitoring system for microservice systems with extended Berkeley Packet Filter (eBPF). Kmon can provide multiple kinds of run-time information of micrservices such as latency, topology, performance metrics with a low overhead.},
  doi={10.1109/CloudIntelligence52565.2021.00014},
  booktitle={2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence)},
  chapter={0}
}

@article{rayyan-384038141,
  title={SeRSS: a storage mesh architecture to build serverless reliable storage services - 2022 30th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)},
  year={2022},
  month={3},
  issn={2377-5750},
  pages={88-91},
  author={Carrizales-Espinoza, Diana and Sánchez-Gallegos, Dante D. and Gonzalez-Compean, J. L. and Carretero, Jesus and Marcelin-Jimenez, Ricardo},
  keywords={Cloud computing;Architecture;Image edge detection;Organizations;Containers;Reliability engineerin...},
  abstract={Cloud storage has been the solution for organizations to manage the exponential growth of data observed over the past few years. However, end-users still suffer from side-effects of cloud service outages, which particularly affect edge-fog-cloud environments. This paper presents SeRSS, a storage mesh architecture to create and operate reliable, configurable, and flexible serverless storage services for heterogeneous infrastructures. A case study was conducted based on-the-fly building of storage services to manage medical imagery. The experimental evaluation revealed the efficiency of SeRSS to manage and store data in a reliable manner in heterogeneous infrastructures.},
  doi={10.1109/PDP55904.2022.00022},
  booktitle={2022 30th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)},
  chapter={0}
}

@article{rayyan-384038142,
  title={Towards a Stateless Cloud Native and Cloud Agnostic Digital Twin Platform for the Digital Product Passport: Out-of-the-box, Reliable, and Scaling - 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
  year={2024},
  month={9},
  issn={1946-0759},
  pages={1-8},
  author={Redeker, Magnus and Simikin, Sven and Marek, Frank},
  keywords={Connectors;Condition monitoring;Costs;Microservice architectures;Switches;Digital twins;Servers;S...},
  abstract={Interoperable digital twins (DT) simplify and automate the implementation of Industry 4.0 (I4.0) use cases like Collaborative Condition Monitoring (CCM), Product and Corporate Carbon Footprint (PCF, CCF) and the Digital Product Passport (DPP) - aiming at adaptivity, resource-efficiency, user-friendliness, compliance with legal requirements and value-creation. Platforms accelerate the development and deployment of DTs and services and ensure their resilient operation in order to capture especially all relevant shop-floor information, for example to aggregate PCFs, CCFs, and DPPs or to report on sustainability - automatically. However, platform operators should in particular avoid cloud provider lock-ins to be able to react flexibly to use case requirements at any time. The technology must be manageable and costs must be controllable. The aim is to achieve a break-even point between security, costs, future viability and controllability, short implementation time and motivated use. Such requirements can currently only be met with cloud infrastructures. An agnostic design ensures that switching infrastructures is possible and can be done both securely and quickly. To this end, this paper develops an out-of-the-box cloud native and cloud agnostic DT platform providing specialized, stateless, loosely coupled DT services interacting within a service mesh. The developed platform meets the requirements, can easily be executed in any public, private and hybrid cloud, and can be scaled horizontally without any further ado.},
  doi={10.1109/ETFA61755.2024.10710875},
  booktitle={2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
  chapter={0}
}

@article{rayyan-384038143,
  title={Coupling Orchestration and DNS for Seamless Service Migration in the Edge–Cloud Continuum - 2025 IEEE 33rd International Conference on Network Protocols (ICNP)},
  year={2025},
  month={9},
  issn={2643-3303},
  pages={1-6},
  author={Dalgitsis, Michail and Datsika, Eftychia and Palacín, Marc and Liu, Peini and Sánchez, Javier Santaella and Serrano, Maria A. and Antonopoulos, Angelos},
  keywords={Couplings;Protocols;Pipelines;Routing;Delays;Logic;Monitoring;Engines;Service migration;DNS orche...},
  abstract={Modern distributed applications increasingly span an edge-cloud continuum, where services may need to dynamically migrate between far-edge, near-edge, and cloud environments to meet latency, resource, or policy constraints. Ensuring seamless service continuity during such migrations remains a significant challenge, particularly due to delays in DNS resolution and inconsistent client routing. This paper presents a modular DNS-driven orchestration framework designed for Kubernetes-based infrastructures. Our approach integrates service orchestration logic with a shared DNS component to enable fast and autonomous service redirection without relying on public DNS providers or complex service meshes. By coupling orchestrator-triggered migrations with DNS record updates, the system ensures immediate service reachability after migration. An optional analytics and decision engine complements the framework by triggering orchestrator actions based on monitoring insights. We evaluate the DNS reconfiguration performance of our solution compared to traditional ExternalDNS-based architectures, demonstrating significantly lower propagation latency and higher determinism during service migrations across the edge–cloud continuum.},
  doi={10.1109/ICNP65844.2025.11192408},
  booktitle={2025 IEEE 33rd International Conference on Network Protocols (ICNP)},
  chapter={0}
}

@article{rayyan-384038144,
  title={A Survey on Observability of Distributed Edge & Container-Based Microservices},
  year={2022},
  journal={IEEE Access},
  issn={2169-3536},
  volume={10},
  pages={86904-86919},
  author={Usman, Muhammad and Ferlin, Simone and Brunstrom, Anna and Taheri, Javid},
  keywords={Monitoring;Observability;Cloud computing;Microservice architectures;Computer architecture;Industr...},
  abstract={Edge computing is proposed as a technical enabler for meeting emerging network technologies (such as 5G and Industrial Internet of Things), stringent application requirements and key performance indicators (KPIs). It aims to alleviate the problems associated with centralized cloud computing systems by placing computational resources to the network’s edge, closer to the users. However, the complexity of distributed edge infrastructures grows when hosting containerized workloads as microservices, resulting in hard to detect and troubleshoot outages on critical use cases such as industrial automation processes. Observability aims to support operators in managing and operating complex distributed infrastructures and microservices architectures by instrumenting end-to-end runtime performance. To the best of our knowledge, no survey article has been recently proposed for distributed edge and containerized microservices observability. Thus, this article surveys and classifies state-of-the-art solutions from various communities. Besides surveying state-of-the-art, this article also discusses the observability concept, requirements, and design considerations. Finally, we discuss open research issues as well as future research directions that will inspire additional research in this area.},
  doi={10.1109/ACCESS.2022.3193102},
  chapter={0}
}

@article{rayyan-384038145,
  title={Model Based Control for Microservices Applications - 2020 IEEE Infrastructure Conference},
  year={2020},
  month={10},
  pages={i-i},
  author={Guha, Aloke},
  keywords={Microservice architectures;Cloud computing;Predictive models;Machine learning;Testing;Monitoring;...},
  abstract={Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The move to cloud to leverage agility and scale initiated a fundamental shift from monolithic to microservices based applications. While they improved modular development, testing, and frequent improvements, microservices create significant challenges for Operations teams. These challenges result from application structure and behavior variability, shifting bottlenecks, and limited visibility and control of cloud infrastructure resources and services. Traditional performance management approaches such as queueing networks are not feasible for microservice applications given the lack of in-depth knowledge of the application structure and inability to handle the complexity of such systems at scale. Using heuristics that capture static relationships between performance and resources are also no longer applicable with highly dynamic virtual cloud resources. We propose a new model-based control for managing application performance. Relying on existing monitoring data and without instrumenting the application, we discover and build the application structure. Subsequently, using both machine learning (ML) and a priori knowledge of known services, we build a predictive application behavior model. The model is generated with sufficient granularity to detect anomalies that predict emerging performance problems. We then apply knowledge-based reasoning on insights from the anomaly analysis and dependencies within the application to recommend remedial actions to the infrastructure and services for problem resolution.},
  doi={10.1109/IEEECONF47748.2020.9377616},
  booktitle={2020 IEEE Infrastructure Conference},
  chapter={0}
}

@article{rayyan-384038146,
  title={An empirical study on the performance overhead of code instrumentation in containerised microservices},
  year={2025},
  journal={Journal of Systems and Software},
  volume={230},
  author={Hammad, Yasmeen and Al-Said Ahmad, Amro and Andras, Peter Peter},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010556599&doi=10.1016%2Fj.jss.2025.112573&partnerID=40&md5=573aa6fa77d780c6dfcc0f7fd879ba22},
  keywords={Application programming interfaces (API), Automated code, Cloud applications, Cloud computing, Cloud container, Cloud-computing, Code instrumentation, Codes (symbols), Containers, Distributed database systems, Errors, Microservice, Open source software, Open systems, Overhead performance, Performance, Response time (computer systems), Starting, Statistics, Throughput, Time latency},
  abstract={Code instrumentation is vital for analysing software behaviour and facilitating cloud computing observability and monitoring, especially in microservices and containers. Despite its benefits, instrumentation introduces complexity and performance overhead, which may inadvertently slow down systems and cause unexpected or erratic behaviour. In this study, we examine the effect of automated code instrumentation on the performance of containerised microservices by comparing instrumented systems against a baseline without instrumentation. Our experimental framework is based on key performance metrics, including response time, latency, throughput, and error percentage. It is executed using a rigorous methodology with a warm-up strategy to mitigate cold-start effects. Over 5000 experiments were conducted on 70 microservice APIs drawn from two open-source applications hosted on AWS and Azure to compare the results with baseline data. The experimental analysis comprises three stages: a pilot study on AWS, a case study on AWS and Azure, and an outlier analysis of the experimental results. Overall throughput decreased by up to 8.40 \%, with some individual cases experiencing up to a 30 \% reduction compared to the baseline, and response time and latency dropped by 20–49 \%. Moreover, the results show more outlier cases in instrumentation results than in the baseline. Additionally, the results reveal more outlier cases in the instrumentation results compared to the baseline. The instrumentation has led to unexpected or erratic behaviour, as indicated by higher variations in response time, latency, and throughput values, along with increased error rates and occasional outlier values that were not observed in the non-instrumented run. This indicates that the performance differences we observed are attributable to overhead introduced by instrumentation, rather than inherent inefficiencies within the APIs themselves. Furthermore, statistical analysis utilised the Wilcoxon Signed-Rank test and mean ratios, with multiple approaches validating significant performance differences between instrumented and baseline conditions for both cloud services. A significance analysis using Cohen's d indicates that the throughput and response time reductions in both platforms are not only statistically significant but also suggest considerable operational impact. These findings offer insights into automated code instrumentation's performance and impact on containerised microservices. It highlights the need to develop better and less impactful instrumentation techniques, and possibly towards the development of a new approach for large-scale software development and deployment in cloud environments that facilitates efficient instrumentation by design. © 2025 Elsevier B.V., All rights reserved.},
  note={Type: Article},
  doi={10.1016/j.jss.2025.112573},
  chapter={0}
}

