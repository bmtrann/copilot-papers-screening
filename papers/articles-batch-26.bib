@article{rayyan-384038202,
  title={Telemetry-{Driven} {Microservices} {Orchestration} in {Cloud}-{Edge} {Environments} - {IEEE} {International} {Conference} on {Cloud} {Computing}, {CLOUD}},
  year={2024},
  pages={91 -- 101},
  author={Marchese, Angelo and Tomarchio, Orazio},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203238024&doi=10.1109%2FCLOUD62652.2024.00020&partnerID=40&md5=b23e9a3cb25595f4e96a359f2f0c0655},
  keywords={Cloud platforms, Telemetering, Telemetering systems, Cloud data centers, Distributed cloud, Microservice application, Cloud-to-edge continuum, Container scheduling, Container technol-ogy, Distributed clouds, Kubernetes descheduler, Kubernetes scheduler, Observabil-ity, Scheduling process},
  abstract={The orchestration of distributed microservices-based applications, particularly within geo-distributed Cloud-to-Edge environments, poses significant challenges. While Kubernetes stands as the predominant container orchestration standard in Cloud data centers, its static container scheduling approach presents limitations in deploying complex, distributed microservices-based applications across Edge environments. Presently, the scheduling process in Kubernetes fails to consider current infrastructure network conditions, resource usage, or runtime application statecrucial factors for mitigating the heterogeneous and dynamic nature of Cloud-to-Edge infrastructure and optimizing application response times. In this study, we propose an enhancement of the Kubernetes platform by implementing a load and network-aware microser-vices scheduling and orchestration strategy. The idea is to extend the Kubernetes control and scheduling logic with a dynamic orchestration strategy, continuously adapting application place-ment based on the real-time state of both the infrastructure and the application itself. We evaluate the efficacy of our approach by comparing it with the default Kubernetes orchestration and scheduling strategy. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1109/CLOUD62652.2024.00020},
  booktitle={{IEEE} {International} {Conference} on {Cloud} {Computing}, {CLOUD}},
  chapter={0}
}

@article{rayyan-384038205,
  title={Sasquatch: {Rubin} {Observatory} metrics and telemetry service - Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
  year={2024},
  volume={13101},
  author={Neto, Angelo Fausti and Economou, Frossie and Reuter, Michael A. and Sick, Jonathan N. and Allbery, Russ and Thornton, Adam J.},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201972878&doi=10.1117%2F12.3019081&partnerID=40&md5=3015c6de5c656b429ed841f3524bf1a3},
  keywords={Telemetry data, Network security, Time-series data, Metric, Engineering data, High frequency HF, LSST, Metadata, Optical fibers, Performance metrices, Photonics, Photons, Query time, Time Series Database, Vera C rubin observatory},
  abstract={At Vera C. Rubin Observatory, the need to manage metrics and telemetry data efficiently led to the creation of Sasquatch. Sasquatch consolidates our high-frequency telemetry harness, which captures the observatory engineering data, with the science performance metrics measured by the LSST Science Pipelines. Sasquatch utilizes InfluxDB, a time series database, to efficiently store and query time-series data. We combine InfluxDB Enterprise with Apache Kafka and deploy our solution on the Kubernetes platform. Our current setup at the US Data Facility enables real-time access to data mirrored from the Summit and leverages tools like Chronograf for time series data visualization, Kapacitor for alert management, and the Rubin Science Platform’s notebook environment for data analysis using Python. Sasquatch is currently employed during Rubin Observatory’s System Integration Testing and Commissioning phase and is an essential service as we transition into survey operations. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1117/12.3019081},
  booktitle={Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
  chapter={0}
}

@article{rayyan-384038206,
  title={A unit testing approach to developing an industrial real time distributed control system for the {New} {Robotic} {Telescope} - Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
  year={2024},
  volume={13101},
  author={Garner, Adam and Bento, João Da Silva and Copley, David and Heffernan, David and Miossec, Chloé},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201960439&doi=10.1117%2F12.3019827&partnerID=40&md5=824b561c4b2859cc6aa2d50bf5e18506},
  keywords={Computer debugging, Airborne telescopes, Beckhoff, Data bus, Digital control systems, Digital storage, EtherCAT, Industrial robots, New robotic telescope, OPC-UA, Optical telescopes, PLC, Redundancy, Robot programming, Robotic telescope, Robust control, Robustness (control systems), Time varying control systems, Unit testing},
  abstract={The New Robotic Telescope (NRT) is a fully autonomous robotic four-meter class telescope located at the Roque de los Muchachos Observatory (ORM) on La Palma, Canary Islands, Spain. The autonomous nature requires a robust, fault tolerant, real time Control System. This is achieved by using proven industrial Beckhoff PLCs and an Ethercat data bus for real time operation. The Ethercat data bus is used to link all pieces of PLC hardware together, this drastically cuts down on the number of control cables going through rotators and cable wraps and increases reliability with a ring topology giving cable redundancy. The PLC code is developed using a Unit testing framework which lowers the risk of breaking expensive hardware during code changes and allows extra functionality to be added easily. This is being implemented to allow new hardware to be added easily and old hardware can later be swapped out for newer models, lowering maintenance costs. The PLCs are controlled by a Kubernetes Cluster using the OPC-UA protocol. The telescope functional safety will be tightly integrated with Beckhoff Twinsafe allowing complete telemetry all the way up the software stack. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1117/12.3019827},
  booktitle={Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
  chapter={0}
}

@article{rayyan-384038208,
  title={{ACES} - {Autopoietic} {Cognitive} {Edge}-cloud {Services} - {CEUR} {Workshop} {Proceedings}},
  year={2024},
  volume={3737},
  author={Remotti, Luca Alessandro and Senfett, Chiara and Meloni, Maria Patrizia},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200762185&partnerID=40&md5=7276a10ba6ff7e5646b018ad35a4dce0},
  keywords={Distributed database systems, Computer architecture, Web services, Edge computing, Application programs, Cloud computing architecture, Resource allocation, Complex networks, Software reliability, Digital storage, Autopoiesis, Cloud managements, Cloud services, Cognition, Edge services, Edge to cloud continuum, Information management, Natural resources management, Resource management, Resource policy, Sensitive data, Service management},
  abstract={The increasing need for cloud services at the edge (edge-services) is caused by the rapidly growing quantity and capabilities of connected and interacting edge devices exchanging vast amounts of data. This poses different challenges to cloud computing architectures at the edge, such as i) ability to provide end-to-end transaction resiliency of applications broken down in distributions of microservices; ii) creating reliability and stability of automation in cloud management under increasing complexity iii) secure and timely handling of the increasing and latency sensitive flow (east-west) of sensitive data and applications; iv)need for explainable AI and transparency of the increasing automation in edge-services platform by operators, software developers and end-users. ACES will solve these challenges by infused autopoiesis and cognition on different levels of cloud management to empower with AI different functionalities such as: workload placement, service and resource management, data and policy management. ACES key outcomes will be: i) autopoiesis cognitive cloud-edge framework; ii) awareness tools, AI/ML agents for workload placement, service and resource management, data and policy management, telemetry and monitoring; iii) agents safeguarding stability in situations of extreme load and complexity; iv) swarm technology-based methodology and implementation for orchestration of resources in the edge; v) edge-wide workload placement and optimization service; vi) an app store for classification, storage, sharing and rating of AI models used in ACES. ACES will be demonstrated and validated in 3 scenarios demanding for support of highly decentralised computing, ability to take autonomic decisions, reducing costs of cloud-edge management and increasing their efficiency, thus reducing impact on environment. To foster the uptake of ACES outcomes beyond its lifespan, different activities are foreseen to drive adoption to a wider network of stakeholders in key sectors. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  booktitle={{CEUR} {Workshop} {Proceedings}},
  chapter={0}
}

@article{rayyan-384038211,
  title={Vnode: {Low}-{Overhead} {Transparent} {Tracing} of {Node}.js-{Based} {Microservice} {Architectures}},
  year={2024},
  journal={Future Internet},
  volume={16},
  number={1},
  author={Kabamba, Herve M. and Khouzam, Matthew and Dagenais, Michel R.},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183385088&doi=10.3390%2Ffi16010013&partnerID=40&md5=3aacd5f98a572665c1b505bab4aac8c7},
  keywords={Microservice, Performance, Distributed tracing, Architecture, Economic and social effects, Debugging, Js, Node., Performance debugging, Trace analysis, Trace context, Trace files, Transparent tracing},
  abstract={Tracing serves as a key method for evaluating the performance of microservices-based architectures, which are renowned for their scalability, resource efficiency, and high availability. Despite their advantages, these architectures often pose unique debugging challenges that necessitate trade-offs, including the burden of instrumentation overhead. With Node.js emerging as a leading development environment recognized for its rapidly growing ecosystem, there is a pressing need for innovative performance debugging approaches that reduce the telemetry data collection efforts and the overhead incurred by the environment’s instrumentation. In response, we introduce a new approach designed for transparent tracing and performance debugging of microservices in cloud settings. This approach is centered around our newly developed Internal Transparent Tracing and Context Reconstruction (ITTCR) technique. ITTCR is adept at correlating internal metrics from various distributed trace files to reconstruct the intricate execution contexts of microservices operating in a Node.js environment. Our method achieves transparency by directly instrumenting the Node.js virtual machine, enabling the collection and analysis of trace events in a transparent manner. This process facilitates the creation of visualization tools, enhancing the understanding and analysis of microservice performance in cloud environments. Compared to other methods, our approach incurs an overhead of approximately 5\% on the system for the trace collection infrastructure while exhibiting minimal utilization of system resources during analysis execution. Experiments demonstrate that our technique scales well with very large trace files containing huge numbers of events and performs analyses in very acceptable timeframes. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Article},
  doi={10.3390/fi16010013},
  chapter={0}
}

@article{rayyan-384038218,
  title={Research on the {Application} of {Real} {Time} {Data} {Analysis} {System} for {Flight} {Test} {Based} on {Microservices}},
  year={2023},
  pages={1048 -- 1054},
  author={Nie, Yaojia},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191502388&doi=10.1145%2F3650400.3650577&partnerID=40&md5=f9c2080d3183084b3557b76fc61ecb64},
  keywords={Data handling, Scalability, Information management, Data analysis system, Deep learning, Density diagram, Disorder of consciousness, Flight test, Information analysis, Phase-Locking values, Power spectral density, Power spectral density diagram, Real time data analysis, Real time monitoring system, Tight integrations},
  abstract={In order to solve the problem of increasing upgrade difficulty and insufficient scalability caused by the tight integration of real-time monitoring system programs and high coupling of various module functions in the current flight test, and to improve the flexibility of telemetry data real-time analysis, a distributed flight test real-time data analysis system based on microservices is designed. The system adopts a microservices architecture to separate traditional business from new business, The use of a service registry for centralized management of services enables flexible real-time data analysis functionality. The practical results indicate that the system based on microservices has good scalability and solves the urgent need for system expansion brought about by real-time data analysis. © 2024 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1145/3650400.3650577},
  chapter={0}
}

@article{rayyan-384038219,
  title={Auto-tuning elastic applications in production - Proceedings - {International} {Conference} on {Software} {Engineering}},
  year={2023},
  pages={355 -- 367},
  author={Sampaio, Adalberto R. and Beschastnikh, Ivan and Maier, Daryl and Bourne, Don and Sundaresen, Vijay},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171786242&doi=10.1109%2FICSE-SEIP58684.2023.00038&partnerID=40&md5=4f0fd124ff0ecae07523ee8df48ffc49},
  keywords={Cloud applications, Codes (symbols), Microservice, Performance, Kubernetes, Instrument testing, Cloud environments, Scalings, Application codes, Autotuning, Elastic applications, Elastic cloud environment},
  abstract={Modern cloud applications must be tuned for high performance. Yet, a single static configuration is insufficient since a cloud application must deal with changes in workload, varying numbers of replicas due to auto-scaling, and upgrades to the environment and the application code itself. These dynamics can only be observed altogether during the application execution and affects different layers of the application stack. In this paper, we describe SmartTuning, a technique and tool to auto-tune cloud applications on the fly, improving resource utilization and performance under dynamic workloads. SmartTuning reacts to different workloads over time and automatically explores and adapts the application's configuration through Bayesian Optimization. SmartTuning searches for configurations that better use resources when the application is subject to auto-scaling and dynamic workloads. It minimizes the need for the operations team to instrument code or manually try out configurations in testing environments. Our evaluation of three industrial applications indicates that SmartTuning can, on average, improve application efficiency by 58\% and reduce cost by 27\%. © 2025 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1109/ICSE-SEIP58684.2023.00038},
  booktitle={Proceedings - {International} {Conference} on {Software} {Engineering}},
  chapter={0}
}

@article{rayyan-384038220,
  title={Murphy: {Performance} {Diagnosis} of {Distributed} {Cloud} {Applications}},
  year={2023},
  pages={438 -- 451},
  author={Harsh, Vipul and Zhou, Wenxuan and Ashok, Sachin and Mysore, Radhika Niranjan and Godfrey, Philip Brighten and Banerjee, Sujata},
  url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174041751&doi=10.1145%2F3603269.3604877&partnerID=40&md5=05c13ea5232678b8d0ab41e3459205e9},
  keywords={Cloud applications, Microservice, Distributed cloud, Distributed applications, Cloud-based applications, Markov processes, Performance diagnosis, Distributed clouds, Cyclic dependencies, Enterprise environment, Enterprise networks, Inter-dependencies},
  abstract={Modern cloud-based applications have complex inter-dependencies on both distributed application components as well as network infrastructure, making it difficult to reason about their performance. As a result, a rich body of work seeks to automate performance diagnosis of enterprise networks and such cloud applications. However, existing methods either ignore inter-dependencies which results in poor accuracy, or require causal acyclic dependencies which cannot model common enterprise environments.We describe the design and implementation of Murphy, an automated performance diagnosis system, that can work with commonly available telemetry in practical enterprise environments, while achieving high accuracy. Murphy utilizes loosely-defined associations between entities obtained from commonly available monitoring data. Its learning algorithm is based on a Markov Random Field (MRF) that can take advantage of such loose associations to reason about how entities affect each other in the context of a specific incident. We evaluate Murphy in an emulated microservice environment and in real incidents from a large enterprise. Compared to past work, Murphy is able to reduce diagnosis error by ≈ 1.35× in restrictive environments supported by past work, and by ≥ 4.7× in more general environments. © 2023 Elsevier B.V., All rights reserved.},
  note={Type: Conference paper},
  doi={10.1145/3603269.3604877},
  chapter={0}
}

